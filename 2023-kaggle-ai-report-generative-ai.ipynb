{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8db697",
   "metadata": {
    "papermill": {
     "duration": 0.01449,
     "end_time": "2023-07-13T14:19:56.357294",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.342804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"text-align: center; font-family: Palatino; font-size: 38px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: blue; background-color: #ffffff;\">2023 Kaggle AI Report on Generative AI </h1>\n",
    "<h5 style=\"text-align: center; font-family: Palatino; font-size: 20px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; color: black; background-color: #ffffff;\">Created By: Trushant Kalyanpur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8733f",
   "metadata": {
    "papermill": {
     "duration": 0.012189,
     "end_time": "2023-07-13T14:19:56.382501",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.370312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/WJeMnOm.png\" width=\"900\" height=\"700\" class=\"center\"/></p>\n",
    "<a href=\"https://appen.com/blog/launching-generative-ai-application-four-principles-critical-to-success/\"><p style=\"text-align:center\">Image credit Appen</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db08e97",
   "metadata": {
    "papermill": {
     "duration": 0.012386,
     "end_time": "2023-07-13T14:19:56.408181",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.395795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p id=\"toc\"></p>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<h1 style=\"font-family: Palatino; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: blue; background-color: #ffffff;\">TABLE OF CONTENTS</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#intro\">1&nbsp;&nbsp;&nbsp;&nbsp;INTRODUCTION</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#background\">2&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#2021\">3&nbsp;&nbsp;&nbsp;&nbsp;YEAR 2021</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#2022\">4&nbsp;&nbsp;&nbsp;&nbsp;YEAR 2022</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#2023\">5&nbsp;&nbsp;&nbsp;&nbsp;YEAR 2023</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#conclusion\">6&nbsp;&nbsp;&nbsp;&nbsp;CONCLUSION</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#fwd\">7&nbsp;&nbsp;&nbsp;&nbsp;LOOKING FORWARD</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#ref\">8&nbsp;&nbsp;&nbsp;&nbsp;REFERENCES</a></h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"font-family: Palatino;color: black; font-size: 20px; letter-spacing: 2px;\"><a href=\"#ref\">9&nbsp;&nbsp;&nbsp;&nbsp;CITATIONS</a></h3>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1ac3d",
   "metadata": {
    "papermill": {
     "duration": 0.01228,
     "end_time": "2023-07-13T14:19:56.434990",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.422710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"intro\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 1. Introduction </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#intro\">Â¶</a></h1>\n",
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/g9EAjKF.png\" width=\"600\" height=\"400\" class=\"center\"/></p>\n",
    "<a href=\"https://unsplash.com/photos/W87RB3CmL3o\"><p style=\"text-align:center\">Image credit Brett Jordan</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c661d6a",
   "metadata": {
    "papermill": {
     "duration": 0.012484,
     "end_time": "2023-07-13T14:19:56.460126",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.447642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp;This report highlights the most significant events in the field of generative AI between 2021 and 2023. Generative AI has seen remarkable advancements during this period, with breakthroughs in image synthesis, audio and language models. The following sections discuss notable developments and achievements in the field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561f4f3",
   "metadata": {
    "papermill": {
     "duration": 0.012598,
     "end_time": "2023-07-13T14:19:56.485685",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.473087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230182e",
   "metadata": {
    "papermill": {
     "duration": 0.01273,
     "end_time": "2023-07-13T14:19:56.511211",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.498481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"background\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 2. Background </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#background\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c41f33",
   "metadata": {
    "papermill": {
     "duration": 0.012479,
     "end_time": "2023-07-13T14:19:56.536735",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.524256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; Before we dive into the advancements in Generative AI over the last two years, it is important to understand the significance of the Generative Pre-trained Transformer (GPT). GPT is a family of large-scale language models developed by OpenAI. The underlying architecture of GPT was based on the [Transformer](https://arxiv.org/abs/1706.03762) which is the classic encoder decoder architecture. The encoder processes the input sequence, while the decoder generates an output sequence based on the encoded information. The paper [Generating Wikipedia by Summarizing Long Sequences](https://arxiv.org/pdf/1801.10198.pdf) proposed another arrangement of the transformer block that is capable of doing language modeling. This model threw away the transformer encoder and only used a stack of decoders. The GPT models also use a similar architecture which consists of a stack of many decoders. The GPT models are autoregressive in nature, which means that the model predicts the next value in a sequence based on the previous values in the sequence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcadc9",
   "metadata": {
    "papermill": {
     "duration": 0.012493,
     "end_time": "2023-07-13T14:19:56.562214",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.549721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/CNP0S4i.png\" width=\"600\" height=\"800\" class=\"center\"/></p>\n",
    "<a href=\"http://jalammar.github.io/illustrated-gpt2/\"><p style=\"text-align:center\">Image credit Jay Alammar</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bb241",
   "metadata": {
    "papermill": {
     "duration": 0.013389,
     "end_time": "2023-07-13T14:19:56.588250",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.574861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; The chart below shows the timeline of GPT releases. GPT1 released in 2018, had 117 million params and it was trained on a diverse range of internet text data. It was a groundbreaking language model that demonstrated significant advancements in generating human-like text based on a given prompt or context. GPT2 released in 2019, was 1.5 billion parameters and showcased an impressive ability to generate coherent and contextually relevant text samples. GPT3 released in June 2020, was a massive model with 175 billion parameters trained on Common Crawl, WebText2 and Wikipedia and demonstrated remarkable text generation capabilities and showcased advancements in natural language understanding and synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715abcf8",
   "metadata": {
    "papermill": {
     "duration": 0.012608,
     "end_time": "2023-07-13T14:19:56.613905",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.601297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/fhXCY1J.png\" width=\"700\" height=\"900\" class=\"center\"/></p>\n",
    "<a href=\"https://www.tooltester.com/en/blog/chatgpt-statistics/\"><p style=\"text-align:center\">Image credit tooltester.com</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c5e27",
   "metadata": {
    "papermill": {
     "duration": 0.014015,
     "end_time": "2023-07-13T14:19:56.641351",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.627336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">ðŸ“Œ GPT significantly advanced the state of the art in natural language processing, showcasing the potential of large-scale language models for a wide range of language-related tasks including text completion, summarization, dialogue generation, and story writing. The architecture would be used as a building block in the years to come to build even more exciting and signficant models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36d9cb",
   "metadata": {
    "papermill": {
     "duration": 0.012672,
     "end_time": "2023-07-13T14:19:56.667255",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.654583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9b3ef",
   "metadata": {
    "papermill": {
     "duration": 0.012705,
     "end_time": "2023-07-13T14:19:56.692992",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.680287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"2021\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 3. Year 2021 </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#2021\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbade6",
   "metadata": {
    "papermill": {
     "duration": 0.015471,
     "end_time": "2023-07-13T14:19:56.722605",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.707134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"dalle\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 3.1 DALL-E : A significant milestone in text-to-image generation</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#dalle\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d0b47",
   "metadata": {
    "papermill": {
     "duration": 0.012907,
     "end_time": "2023-07-13T14:19:56.748877",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.735970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp;In 2021, OpenAI released [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092) a text-to-image generation model called DALL-E. It is a 12-billion parameter multimodal (text + image) implementation of GPT-3 trained to generate images from text descriptions, using a dataset of text-image pairs. DALL-E was revealed around the same time as Contrastive Language-Image Pretraining [(CLIP)](https://arxiv.org/abs/2103.00020). The key objective of CLIP was to train a model that could understand and relate images and their corresponding textual descriptions in a coherent manner. By leveraging large-scale datasets (400 million) of image-text pairs from the internet, CLIP aimed to learn visual representations that could be applied to various downstream tasks. OpenAI used CLIP to help evaluate Dall-E's output by analyzing which caption is most suitable for a generated image. The method of DALL-E is called the inverted clip, or unCLIP, because it does the opposite of what CLIP does, by generating images from text instead of making text from images.\n",
    "  <br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; With DALL-E's debut, came fears about the end of creativity especially for artists, graphic designers and illustrators. On the upside, its ability to generate unique and visually appealing images with very fine-grained details based on textual input, sparked creativity and new ideas for various creative endeavors including storytelling and concept art. It enabled users to express their ideas or concepts through natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ad5bf",
   "metadata": {
    "papermill": {
     "duration": 0.012627,
     "end_time": "2023-07-13T14:19:56.774364",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.761737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/yMr3cPk.png\" width=\"800\" height=\"900\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\">Example prompt <em><strong>\"An astronaut riding a horse in photorealistic style\"</em></strong> using DALL-E</p>\n",
    "<a href=\"https://openai.com/dall-e-2\"><p style=\"text-align:center\">Image credit OpenAI</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c05d0",
   "metadata": {
    "papermill": {
     "duration": 0.012755,
     "end_time": "2023-07-13T14:19:56.800089",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.787334",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df840b51",
   "metadata": {
    "papermill": {
     "duration": 0.012578,
     "end_time": "2023-07-13T14:19:56.825524",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.812946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"copilot\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 3.2 Github Co-Pilot: A breakthrough coding assistant</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#copilot\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911bb18",
   "metadata": {
    "papermill": {
     "duration": 0.012606,
     "end_time": "2023-07-13T14:19:56.851094",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.838488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; OpenAI also announced Github Copilot based on the GPT-3 architecture in 2021. The model was fine-tuned on millions of lines of public code on GitHub and could be used to auto complete and suggest code based on user comments across multiple programming languages. \n",
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; A significant concern when Github Copilot was released, was the potential infringement of intellectual property rights and licensing issues since the model was trained on all publically available Github code. There is also a risk that the suggested code could contain security vulnerabilities since the model could have been trained on code that contains biases or security flaws. \n",
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; GitHub Copilot has had a notable impact on the developer community by improving productivity. It enables developers to focus on higher-level tasks and problem-solving and reduce the time spent on writing repetitive code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b7d9c",
   "metadata": {
    "papermill": {
     "duration": 0.012473,
     "end_time": "2023-07-13T14:19:56.876580",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.864107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"tenor-gif-embed\" data-postid=\"22702994\" data-share-method=\"host\" data-aspect-ratio=\"1.77778\" data-width=\"100%\"><a href=\"https://tenor.com/view/github-github-copilot-gif-22702994\">Github Github Copilot GIF</a>from <a href=\"https://tenor.com/search/github-gifs\">Github GIFs</a></div> <script type=\"text/javascript\" async src=\"https://tenor.com/embed.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df9ca4",
   "metadata": {
    "papermill": {
     "duration": 0.012739,
     "end_time": "2023-07-13T14:19:56.902319",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.889580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\">Example of function auto code completion in Github Copilot<p style=\"text-align:center;\">\n",
    "<a href=\"https://tenor.com/view/github-github-copilot-gif-22702994\"><p style=\"text-align:center\">Animation credit kingslayerr</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdce29",
   "metadata": {
    "papermill": {
     "duration": 0.012694,
     "end_time": "2023-07-13T14:19:56.927969",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.915275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">ðŸ“Œ 2021 marked a year in Generative AI where:\n",
    "<ul>\n",
    "  <li> Text-to-image models came to prominence with the launch of DALL-E which pushed the boundaries of image generation by producing unique and imaginative visual content based on textual prompts. </li>\n",
    "  <li> GitHub Copilot launced and has since then, significantly improved developer productivity by suggesting code snippets and completing code. </li>\n",
    "</ul>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808eee0e",
   "metadata": {
    "papermill": {
     "duration": 0.013145,
     "end_time": "2023-07-13T14:19:56.953904",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.940759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a473d3",
   "metadata": {
    "papermill": {
     "duration": 0.012466,
     "end_time": "2023-07-13T14:19:56.979210",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.966744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"2022\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 4. Year 2022 </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#2022\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299464c",
   "metadata": {
    "papermill": {
     "duration": 0.012507,
     "end_time": "2023-07-13T14:19:57.004661",
     "exception": false,
     "start_time": "2023-07-13T14:19:56.992154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"palm\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.1 Pathways Language Model (PaLM) </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#palm\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9693afc",
   "metadata": {
    "papermill": {
     "duration": 0.012671,
     "end_time": "2023-07-13T14:19:57.030171",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.017500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; [PaLM](https://arxiv.org/pdf/2204.02311v5.pdf) is a 540B parameter (3x the size of GPT3) large language model (LLM) developed by Google AI. It was designed to be more efficient and scalable than previous LLM architectures, while still achieving state-of-the-art performance on a variety of tasks. PaLM uses Pathways which uses a hierarchical structure of pathways, that allows the model to learn different levels of abstraction about the data. This architecture allowed for scaling the training process to thousands of TPU chips, which is a significant increase compared to other language models. This scaling was achieved using data parallelism, where the data is divided and processed across multiple TPU chips, and model parallelism, where the model is split and processed on a single TPU chip. This architecture enabled the training of a very large model with a large dataset of 780 billion tokens comprising of filtered webpages, books, Wikipedia, news articles, source code and social media conversations.\n",
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; PaLM showed significant improvements over previous language models on a variety of tasks, including text generation, question answering, and machine translation. For example, PaLM was able to generate text that was more factual and creative than text generated by previous language models. It was also able to answer questions more accurately and to translate languages more fluently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11d9b5",
   "metadata": {
    "papermill": {
     "duration": 0.012641,
     "end_time": "2023-07-13T14:19:57.055766",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.043125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/s3phECI.png\" width=\"800\" height=\"900\" class=\"center\"/></p>\n",
    "<a href=\"https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/\"><p style=\"text-align:center\">Image credit Google</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3418dd7",
   "metadata": {
    "papermill": {
     "duration": 0.012603,
     "end_time": "2023-07-13T14:19:57.081331",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.068728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"dalle2\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.2 DALL-E 2</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#dalle2\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38b3d",
   "metadata": {
    "papermill": {
     "duration": 0.012697,
     "end_time": "2023-07-13T14:19:57.106986",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.094289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In April 2022, Open AI released the succesor to DALL-E, the [DALL-E 2](https://arxiv.org/pdf/2204.06125v1.pdf). While DALL-E used a [CLIP](https://arxiv.org/abs/2103.00020) model for re-ranking, DALL-E 2 uses CLIP embeddings directly, and decodes images via a diffusion model instead of a decoder-only transformer. A diffusion model is a type of generative model that works by gradually adding noise to an image until it matches the text description. This allows DALL-E 2 to generate more realistic images, as it is not limited by the need to generate the image one pixel at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec7b7d",
   "metadata": {
    "papermill": {
     "duration": 0.012196,
     "end_time": "2023-07-13T14:19:57.131965",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.119769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/nxaIUES.png\" width=\"800\" height=\"900\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> DALL-E 2 Architecture </p>\n",
    "<a href=\"https://arxiv.org/abs/2204.06125v1\"><p style=\"text-align:center\">Image credit DALL-E-2 paper</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72545b5",
   "metadata": {
    "papermill": {
     "duration": 0.012161,
     "end_time": "2023-07-13T14:19:57.156767",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.144606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The picture above shows the CLIP training process above the dotted line, through which we learn a joint representation space for text and images. Below the dotted line, we depict our text-to-image generation process: a CLIP text embedding is first fed to an autoregressive or diffusion prior to produce an image embedding, and then this embedding is used to condition a diffusion decoder which produces a final image. \n",
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\"> &nbsp;&nbsp;&nbsp;&nbsp; The combination of using CLIP embeddings, a diffusion prior and a diffusion decoder enabled DALL-E 2 to generate more realistic and accurate images vs DALL-E. Below, is an example of the difference in quality for the same prompt. <em><strong>\"a painting of a fox sitting in a field at sunrise in the style of Claude Monet\"</strong></em>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e5373",
   "metadata": {
    "papermill": {
     "duration": 0.012766,
     "end_time": "2023-07-13T14:19:57.182142",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.169376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/JK9Iam5.png\" width=\"800\" height=\"900\" class=\"center\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec651d",
   "metadata": {
    "papermill": {
     "duration": 0.012786,
     "end_time": "2023-07-13T14:19:57.207944",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.195158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"> <strong><em>DALL-E</em> (left)</strong>  vs <strong><em>DALL-E 2</em> (right)</strong> for the same prompt</p>\n",
    "<a href=\"https://openai.com/dall-e-2\"><p style=\"text-align:center\">Photo credit OpenAI</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f5efe",
   "metadata": {
    "papermill": {
     "duration": 0.013267,
     "end_time": "2023-07-13T14:19:57.234202",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.220935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"midj\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.3 Midjourney</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#midj\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d410b1",
   "metadata": {
    "papermill": {
     "duration": 0.012741,
     "end_time": "2023-07-13T14:19:57.260058",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.247317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Midjourney, an image generation model developed by an independent research lab called Midjourney Inc., was released to the public in July 2022. The model's architecture has not been revealed, but its images were generally considered to be of high quality and able to generate a wide variety of different styles and genres. Midjourney was also released in an open beta via Discord, which allowed anyone to sign up and start using the model. This made Midjourney one of the most accessible LLMs for generating images. \n",
    "   <br> <span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The following images show how the quality of images generated by Midjourney has improved over time and across different versions of the model. The images were all generated with the same prompt, but the versions of Midjourney used to generate them ranged from version 1, released in 2022, to version 5, released in March 2023. As you can see, the images generated by newer versions of Midjourney are generally more detailed, realistic, and creative than those generated by older versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b8b00",
   "metadata": {
    "papermill": {
     "duration": 0.012743,
     "end_time": "2023-07-13T14:19:57.285739",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.272996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/gLdrSCY.png\" width=\"900\" height=\"800\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> <strong> Prompt:</strong>  <em> Teenager, female, seventeen years old, pop culture, modern clothing. Photorealistic, Natural lighting, Pastel </em>\n",
    "<a href=\"https://www.linkedin.com/pulse/how-far-midjourney-has-come-just-year-john-severinson/\"><p style=\"text-align:center\">Image credit John Severinson</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526b211",
   "metadata": {
    "papermill": {
     "duration": 0.012622,
     "end_time": "2023-07-13T14:19:57.311506",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.298884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"stablediff\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.4 Stable Diffusion</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#stablediff\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd7e8b",
   "metadata": {
    "papermill": {
     "duration": 0.013233,
     "end_time": "2023-07-13T14:19:57.338496",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.325263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In August 2022, Stable Diffusion a latent diffusion model, capable of generating images from text descriptions was released. This model was particularly signficant because the code and model weights were released publically, making it one of the earliest open source LLMs that generated images from text. It was developed by researchers from the CompVis Group at Ludwig Maximilian University of Munich and Runway with a compute donation by Stability AI and training data from non-profit organizations. It is a latent diffusion model, which means that it uses a latent space to represent the images it generates and it starts with a noisy image and gradually reduces the noise to generate a more realistic image. This allows it to generate images that are more diverse and creative than traditional diffusion models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4051a2",
   "metadata": {
    "papermill": {
     "duration": 0.01337,
     "end_time": "2023-07-13T14:19:57.364544",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.351174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/TpKNMFV.png\" width=\"900\" height=\"800\" class=\"center\"/></p>\n",
    "<a href=\"http://jalammar.github.io/illustrated-gpt2/\"><p style=\"text-align:center\">Image credit Jay Alammar</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf1921",
   "metadata": {
    "papermill": {
     "duration": 0.012598,
     "end_time": "2023-07-13T14:19:57.390518",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.377920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The picture above shows the high level architecture of Stable Diffusion. It has three main components:\n",
    "<ul  style=\"font-family:arial;color:black;font-size:15px;\">\n",
    "  <li> ClipText for text encoding - This takes in a text and outputs the text embedding vectors. </li>\n",
    "  <li> Diffusion: UNet + Scheduler to gradually process/diffuse information in the information (latent) space - This block takes in the text embeddings and an initial tensor made up of noise. It outputs a processed information array.</li>\n",
    "    <li> Autoencoder Decoder - This decoder paints the final image using the processed information array.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e9ba0",
   "metadata": {
    "papermill": {
     "duration": 0.013054,
     "end_time": "2023-07-13T14:19:57.416528",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.403474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The picture below shows a sample prompt and the image generated by Stable Diffusion. The fine-grained details of the intricate armor design, result in a stunning picture of a cat in armor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f20e0",
   "metadata": {
    "papermill": {
     "duration": 0.012789,
     "end_time": "2023-07-13T14:19:57.442706",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.429917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/PgoYDOk.png\" width=\"400\" height=\"500\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> <strong> Prompt:</strong>  <em> kneeling cat knight, portrait, finely detailed armor, intricate design, silver, silk, cinematic lighting, 4k </em></p>\n",
    "<a href=\"https://hostux.social/@valere/108939000926741542?ref=jousefmurad.com\"><p style=\"text-align:center\">Image credit ValÃ¨re</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6faba",
   "metadata": {
    "papermill": {
     "duration": 0.013056,
     "end_time": "2023-07-13T14:19:57.468911",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.455855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"metavid\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.5 Meta announces Make-A-Video</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#metavid\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c546b9",
   "metadata": {
    "papermill": {
     "duration": 0.012921,
     "end_time": "2023-07-13T14:19:57.495201",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.482280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In September 2022, Meta (Facebook) announced [Make-A-Video](https://arxiv.org/pdf/2209.14792.pdf), a LLM that generates videos from text. The model extends a diffusion-based text-to-image (T2I) model to text-to-video (T2V), through a spatiotemporally factorized diffusion model. Make-A-Video consists of three main components,  (1) A base T2I model trained on text-image pairs (2) Spatiotemporal convolution and attention layers that extend the networksâ€™ building blocks to the temporal dimension and (3) Spatiotemporal networks that consist of both spatiotemporal layers, as well as a frame interpolation network for high frame rate generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244cf06c",
   "metadata": {
    "papermill": {
     "duration": 0.012737,
     "end_time": "2023-07-13T14:19:57.520978",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.508241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/qD1uM2T.png\" width=\"700\" height=\"1000\" class=\"center\"/></p>\n",
    "<a href=\"https://arxiv.org/pdf/2209.14792.pdf\"><p style=\"text-align:center\">Image credit Meta AI</a>\n",
    "    \n",
    "<p style=\"text-align:center;\"><img src=\"https://makeavideo.studio/assets/A_teddy_bear_painting_a_portrait.webp\" width=\"500\" height=\"1000\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> <strong> Prompt:</strong>  <em> A teddy bear painting a portrait </em></p>\n",
    "<a href=\"https://makeavideo.studio/\"><p style=\"text-align:center\">Image credit Meta AI</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81a11e",
   "metadata": {
    "papermill": {
     "duration": 0.012682,
     "end_time": "2023-07-13T14:19:57.546629",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.533947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp;Despite not being officially released yet and having a long way to go in terms of video quality, this work exemplifies the possibilities in the text-to-video domain. Similar to early versions of Stable Diffusion and Midjourney, text-to-video models will continue to show more promise over time, eventually reaching a point where it may become nearly impossible to distinguish if a videos was generated solely from a text prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808bc53",
   "metadata": {
    "papermill": {
     "duration": 0.012761,
     "end_time": "2023-07-13T14:19:57.572340",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.559579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"galactica\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.6 Meta releases Galactica</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#galactica\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c22af",
   "metadata": {
    "papermill": {
     "duration": 0.012786,
     "end_time": "2023-07-13T14:19:57.598166",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.585380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In November 2022, Meta (Facebook) released Galactica, a LLM that can store, combine and reason about scientific knowledge according to their submitted [paper](https://galactica.org/static/paper.pdf). The models ranged from 125 Million to 120 Billion parameter. \n",
    " <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In collaboration with Papers with Code, Meta AI open-sourced Galactica and launched a website that allowed visitors to interact with the model. However, three days after Galacticaâ€™s release, Meta had to shut down the online demo following a deluge of criticism by scientists and tech media about the modelâ€™s incorrect and biased output. A fundamental problem with Galactica is that it is not able to distinguish truth from falsehood, a basic requirement for a language model designed to generate scientific text. The explanations it generated sounded authoritative, but they were often subtly incorrect, biased, or just plain wrong.\n",
    "    <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The example below shared on [Twitter](https://twitter.com/Michael_J_Black/status/1593133722316189696?s=20) by Michael Black (Director, Max Planck Institute), shows Galactica citing fictional sources for the query <em>\"Accurate estimation of body shape under clothing from an image\"</em>. It produces an abstract that is plausible but refers to <em>Alldieck et al. \"Accurate Estimation of Body Shape Under Clothing from a Single Image\"</em> which does not exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58deb3cd",
   "metadata": {
    "papermill": {
     "duration": 0.012975,
     "end_time": "2023-07-13T14:19:57.624397",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.611422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/NhiB4G9.png\" width=\"600\" height=\"1000\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> Example hallucination by Galactica</p>\n",
    "<a href=\"https://twitter.com/Michael_J_Black/status/1593133722316189696?s=20\"><p style=\"text-align:center\">Image credit Michael Black</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabef8f3",
   "metadata": {
    "papermill": {
     "duration": 0.012546,
     "end_time": "2023-07-13T14:19:57.649890",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.637344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The release of Galactica was a cautionary tale about the dangers of releasing a large language model which everyone could access and that was specifically marketed as a model that could reason about scientific knowledge. Galacticaâ€™s output can feel real but it was not grounded in real facts.  However, the incident also highlights the importance of carefully evaluating the output of LLMs before using them for important tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01286b76",
   "metadata": {
    "papermill": {
     "duration": 0.012842,
     "end_time": "2023-07-13T14:19:57.675410",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.662568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"chatgpt\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 4.7 ChatGPT - A Tipping Point for Generative AI</span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#chatgpt\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8fe12d",
   "metadata": {
    "papermill": {
     "duration": 0.012577,
     "end_time": "2023-07-13T14:19:57.701601",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.689024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In November 2022, OpenAI released ChatGPT, a generative AI based chatbot that gained worldwide popularity and took the AI world by storm! OpenAI made ChatGPT accessible to everyone for free, and it gained 1 million users in just 5 days. In contrast, Netflix took 3.5 years to get the same amount of users. ChatGPT hit a 100 million monthly active users in January 2023, making it the fastest-growing application in history. \n",
    " <br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; ChatGPT was a versatile language model that could generate chat conversations that were often indistinguishable from human-generated conversations. It could also be used for a variety of other tasks, such as answering questions, generating creative content, providing explanations, offering suggestions, writing poems or code, and more.\n",
    "    <br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp;  The release of ChatGPT was a pivotal moment in the field of artificial intelligence. It showed that language models were capable of achieving a level of sophistication that was previously thought to be impossible. This led to a flurry of activity in the AI community, as other companies rushed to develop their own language models and tools and it is likely that we will see even more impressive language models in the years to come. <br>\n",
    "    <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; ChatGPT was based on the GPT3 architecture, so it is estimated to have around 175 billion parameters. It was fine tuned on a chat specific task where the model was trained on a smaller curated dataset compared to the pretraining data. Human AI trainers and annotators interact with the model and provide rankings for different possible model-generated responses. The model then learns from this feedback and adjusts its responses accordingly. Fine-tuning allows the model to specialize in particular domains or tasks while incorporating human preferences and guidelines. For example, ChatGPT may have been fine-tuned using conversational data, customer support dialogues, or other relevant datasets to make it more suitable for interactive and conversational applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522be2cc",
   "metadata": {
    "papermill": {
     "duration": 0.012839,
     "end_time": "2023-07-13T14:19:57.727174",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.714335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/S4PPgVM.png\" width=\"600\" height=\"1000\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> Example conversation with ChatGPT</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a81eb3",
   "metadata": {
    "papermill": {
     "duration": 0.012696,
     "end_time": "2023-07-13T14:19:57.753033",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.740337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; One of the key techniques used to improve the quality of ChatGPT responses, was the use of Reinforcement Learning from Human Feedback [(RLHF)](https://arxiv.org/abs/2203.02155). RLHF is a technique that trains a language model to generate text that is aligned with human preferences. This is done by collecting feedback from humans on the text that the model generates, and then using that feedback to update the model's parameters. RLHF helped to improve the quality of text generated by ChatGPT, making it more factual, informative, and creative. \n",
    "\n",
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; ChatGPT's success can be seen as a tipping point for generative AI. It showed that LLMs were capable of generating human-quality chat conversations, which opened up the possibility of using LLMs for a wider range of applications. ChatGPT's popularity also helped to raise awareness of generative AI and its potential benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722794b8",
   "metadata": {
    "papermill": {
     "duration": 0.012797,
     "end_time": "2023-07-13T14:19:57.778938",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.766141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">ðŸ“Œ 2022 was a very significant year for Generative AI where:\n",
    "<ul>\n",
    "    <li> Google released PaLM built using the Pathways architecture. PaLM would be the building block for Google's future LLMs.</li>\n",
    "  <li> Text-to-image models were significantly improved with the introduction of DALL-E 2, Midjourney, and Stable Diffusion </li>\n",
    "  <li> Meta announced a text-to-video architecture that levereged diffusion based approaches to generate videos from text.</li>\n",
    "  <li> Meta released Galactica as a scientific LLM, but the community immediately picked up on model hallucinations and text not being grounded in actual facts which is critical  in the scientific field.</li>\n",
    "  <li> ChatGPT showed that LLMs were capable of generating human quality text on a variety of tasks. It was the fastest growing AI application in history and brought Generative AI into the limelight</li>\n",
    "  <li> The AI arms race started with the release of ChatGPT towards the end of 2022.</li>\n",
    "</ul>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301c3a4",
   "metadata": {
    "papermill": {
     "duration": 0.012684,
     "end_time": "2023-07-13T14:19:57.804896",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.792212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dee44",
   "metadata": {
    "papermill": {
     "duration": 0.012591,
     "end_time": "2023-07-13T14:19:57.830302",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.817711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"2023\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 5. Year 2023 </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#2023\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5340e",
   "metadata": {
    "papermill": {
     "duration": 0.012643,
     "end_time": "2023-07-13T14:19:57.855912",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.843269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"llama\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 5.1 Meta Releases LLaMA - Open Source LLMs Explode! </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#llama\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246538ad",
   "metadata": {
    "papermill": {
     "duration": 0.012673,
     "end_time": "2023-07-13T14:19:57.881702",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.869029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In February 2023, Meta released a new large language model (LLM) called LLaMA. LLaMA is a 65-billion parameter model that was trained on a massive dataset of text and code. \n",
    "    <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The LLaMA release was significant for a number of reasons. It was one of the largest LLMs that was released to the public. This means that it has the potential to be used for more complex and challenging tasks than previous LLMs. LLaMA was also open source but the model weights were initially distrubuted to a handful of researchers with the intent of only using the model for research purposes. The model weights landed up being leaked online which means that anyone could download and use it. This event accelerated the development of many LLMS and sparked a series of impressive open source alternatives to ChatGPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeafbd0",
   "metadata": {
    "papermill": {
     "duration": 0.012616,
     "end_time": "2023-07-13T14:19:57.907519",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.894903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/PpToJYE.png\" width=\"900\" height=\"1000\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> <em> A timeline of LLMs including open ource ones (highlighted yellow)</em>\n",
    "<a href=\"https://arxiv.org/pdf/2303.18223.pdf\"><p style=\"text-align:center\">Image credit A Survey of LLMs paper</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a08c6",
   "metadata": {
    "papermill": {
     "duration": 0.012612,
     "end_time": "2023-07-13T14:19:57.933080",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.920468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "  <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The above chart mentioned in the paper [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf), shows the explosion in the number of open source LLMs after the release of LLaMa in January 2023. Huggingface also maintains an open LLM leaderboard [here](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). \n",
    "    <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The Technology Innovation Institute (TII) in Abu Dhabi released Falcon, a notable example of an open source LLM under the Apache 2.0 license. It was the first truly open model with capabilities rivaling many current closed-source models. There were two versions of Falcon: a smaller 7 billion parameter version and a larger 40 billion parameter version. Falcon 40-B requires only 90GB of GPU memory while Falcon-7B only demands around 15GB. The key ingredient for the high quality of the Falcon models is their training data, which is predominantly (more than 80%) based on RefinedWeb, a novel massive web dataset based on CommonCrawl. TII focused on scaling and improving the quality of web data instead of gathering scattered curated sources. They leveraged large-scale deduplication and strict filtering to match the quality of other corpora. The Falcon models still include some curated sources in their training (eg. Reddit), but to a much lesser extent compared to GPT3 or PaLM. The Falcon 40-B currently leads the Hugginface LLM leaderboard. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a3f20",
   "metadata": {
    "papermill": {
     "duration": 0.012415,
     "end_time": "2023-07-13T14:19:57.958144",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.945729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"bard\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 5.2 Google Releases Bard </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#bard\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697371d",
   "metadata": {
    "papermill": {
     "duration": 0.012306,
     "end_time": "2023-07-13T14:19:57.983226",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.970920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Google made a significant move in March 2023 by introducing Bard, a chatbot built on a LLM framework. This release aimed to keep up with the immense hype and popularity surrounding OpenAI's ChatGPT. It was a fine tuned model based on PaLM 2 which had around 340 billion parameters. Bard was trained on a dataset of text and code that was 10 times larger than the dataset that ChatGPT was trained on. Bard also has access to the internet, which means that it could continuously learn and update its knowledge base. This made Bard more up-to-date and accurate than ChatGPT, which was limited to the information that was included in its training dataset which was sometime around September 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9575c",
   "metadata": {
    "papermill": {
     "duration": 0.012419,
     "end_time": "2023-07-13T14:19:58.008408",
     "exception": false,
     "start_time": "2023-07-13T14:19:57.995989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/oIr0AXy.gif\" width=\"900\" height=\"800\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> Example conversation with Bard for the same prompt used for ChatGPT above</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08653c",
   "metadata": {
    "papermill": {
     "duration": 0.012352,
     "end_time": "2023-07-13T14:19:58.033621",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.021269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"gen2\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 5.3 Runway announces Gen-2 for Text-To-Video </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#gen2\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98aefb",
   "metadata": {
    "papermill": {
     "duration": 0.012848,
     "end_time": "2023-07-13T14:19:58.060635",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.047787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In March 2023, Runway (one of the companies behind Stable Diffusion), announced Gen-2, a text to video model. Gen-2 was able to create videos either by applying the composition and style of an image or text prompt to the structure of a source video (Video to Video) or, using nothing but words (Text to Video). Runway showcases a number of examples [here](https://research.runwayml.com/gen2), and one such example is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc08c21",
   "metadata": {
    "papermill": {
     "duration": 0.012793,
     "end_time": "2023-07-13T14:19:58.086657",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.073864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:768x448/1440x840/filters:focal(384x224:385x225):no_upscale():format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24522127/An_aerial_shot_of_a_mountain_landscape.2023_03_20_13_47_36.gif\" width=\"500\" height=\"1000\" class=\"center\"/></p>\n",
    "<p style=\"text-align:center;\"> <strong> Prompt:</strong><em> Aerial drone footage of a mountain range</em>\n",
    "<a href=\"https://research.runwayml.com/gen2\"><p style=\"text-align:center\">Image credit Runway</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09e60e",
   "metadata": {
    "papermill": {
     "duration": 0.012582,
     "end_time": "2023-07-13T14:19:58.112324",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.099742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; There isn't too much detail about the architecture of Gen-2, but needless to say, the world of text-to-video models continues to see advancements with multiple researchers working on bringing high quality video generations to consumers. These tools could be used to create engaging and informative videos for marketing, advertising, social media, and entertainment purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85243789",
   "metadata": {
    "papermill": {
     "duration": 0.01253,
     "end_time": "2023-07-13T14:19:58.137693",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.125163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"qlora\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 5.4 QLoRA </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#qlora\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263ddda",
   "metadata": {
    "papermill": {
     "duration": 0.012695,
     "end_time": "2023-07-13T14:19:58.165089",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.152394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In May 2023, Dettmers et al., 2023, released Quantized LLMs with Low-Rank Adapters [QLoRA](https://arxiv.org/abs/2305.14314). This work was built on the previous work done on LoRA that was released in 2021 by [Hu et al](https://arxiv.org/abs/2106.09685). LoRA is a technique that reduces the memory footprint of large language models (LLMs) by adding a small number of trainable parameters, called adapters, to each layer of the LLM. The original parameters of the LLM are frozen, and only the adapter weights are updated during fine-tuning. This significantly reduces the memory footprint of the model, while still maintaining its performance.\n",
    "<br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp;  QLoRa is an extension of LoRA that goes three steps further by introducing 4-bit quantization, double quantization and paged optmizers which exploits Nvidia's unified memory for paging. QLoRA reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance.\n",
    " <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Instruction finetuning is an essential step on top of pretrained LLMs which can give LLM's ChatGPT-like capabilities. QLoRA enables finetuning for a wider audience that don't have too many compute resources, making it a big win for the accessibility of state of the art NLP technology. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557372a",
   "metadata": {
    "papermill": {
     "duration": 0.012563,
     "end_time": "2023-07-13T14:19:58.190582",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.178019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/BCrFdEN.png\" width=\"900\" height=\"1000\" class=\"center\"/></p>\n",
    "<a href=\"https://arxiv.org/abs/2305.14314\"><p style=\"text-align:center\">Image credit QLoRA paper</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40628a24",
   "metadata": {
    "papermill": {
     "duration": 0.012823,
     "end_time": "2023-07-13T14:19:58.216491",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.203668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"gpt4\"><span style=\"font-family:verdana;color:blue;font-size:25px;\"> 5.5 OpenAI Releases GPT4 </span><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#gpt4\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88877869",
   "metadata": {
    "papermill": {
     "duration": 0.012844,
     "end_time": "2023-07-13T14:19:58.242574",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.229730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; In May 2023, OpenAI released the highly anticipated GPT4. GPT4 was multimodal i.e. accepting image and text inputs, generating text outputs. OpenAI mentioned that they spent 6 months making GPT-4 safer and more aligned. GPT-4 was 82% less likely to respond to requests for disallowed content and 40% more likely to produce factual responses than GPT-3.5 on their internal evaluations. It exhibited human-level performance on various professional and academic benchmarks. For example, it passed a simulated bar exam with a score around the top 10% of test takers. The chart below shows how it does on different exams compared to GTP3.5. It showed impressive results across multiple exams.\n",
    "    <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; There was little revealed about the architecture of GPT4, but recent rumours suggest that it is based on eight models, each with 220 billion parameters, which are linked in the Mixture of Experts (MoE) architecture making it a model with 1.76 Trillion parameters. The MoE model is a type of ensemble learning that combines different models, called \"experts,\" to make a decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18b409",
   "metadata": {
    "papermill": {
     "duration": 0.012997,
     "end_time": "2023-07-13T14:19:58.268869",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.255872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/fUjdJGc.png\" width=\"800\" height=\"600\" class=\"center\"/></p>\n",
    "<a href=\"https://openai.com/research/gpt-4\"><p style=\"text-align:center\">Image credit OpenAI</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243731b",
   "metadata": {
    "papermill": {
     "duration": 0.013038,
     "end_time": "2023-07-13T14:19:58.295138",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.282100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">ðŸ“Œ 2023 saw an explosion in Generative AI fuelled by the ChatGPT launch in late 2022. \n",
    "<ul>\n",
    "  <li> LLaMA was released in January which sparked a wave of high quality open source LLMs like Falcon</li>\n",
    "  <li> Google released Bard to compete with ChatGPT based on PaLM.</li>\n",
    "  <li> Researchers at the University of Washington released QLoRA, an efficient finetuning approach for LLMs. </li>\n",
    "  <li> OpenAI released the multimodal GPT4 with impressive benchmarks on scores on exams across various domains. </li>\n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82747cb",
   "metadata": {
    "papermill": {
     "duration": 0.014327,
     "end_time": "2023-07-13T14:19:58.322946",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.308619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b05a1e",
   "metadata": {
    "papermill": {
     "duration": 0.013062,
     "end_time": "2023-07-13T14:19:58.349793",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.336731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"conclusion\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 6. Conclusion </span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#conclusion\">Â¶</a></h1>\n",
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/Xl9q1Tu.png\" width=\"700\" height=\"800\" class=\"center\"/></p>\n",
    "<a href=\"https://pixabay.com/photos/tunnel-light-hope-mystical-black-3915169/\"><p style=\"text-align:center\">Image credit Tama66</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063a51f",
   "metadata": {
    "papermill": {
     "duration": 0.013589,
     "end_time": "2023-07-13T14:19:58.376462",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.362873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    \n",
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The field of text-to-image generative AI has experienced a remarkable leap forward, exemplified by the impressive advancements seen in models like DALL-E/DALL-E 2, Midjourney, and Stable Diffusion. These models have played a pivotal role in unlocking new possibilities for creative expression, streamlining design processes, and revolutionizing content generation. Notably, they have demonstrated the ability to generate realistic and high-quality images, as evidenced by the earlier examples. However, alongside these advancements, concerns have emerged regarding potential misuse and ethical implications. These powerful text-to-image models have the potential to be utilized for malicious purposes, such as the creation of deepfakes or synthetic media that can be employed to spread misinformation, propaganda, or manipulate public perception. Moreover, there is a risk of these models being misused to generate illegal and toxic content, posing significant challenges in terms of ethical responsibility and content moderation.\n",
    "<br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; GitHub Copilot is a game-changer in how AI assists software developers in their coding endeavors. A [survey](https://gizmodo.com/github-survey-92-percent-programmers-are-using-ai-tools-1850534570) by Github, showed that an astounding 92% of the 500 programmers surveyed, use AI tools to assist them in their workflows. Another [study](https://arxiv.org/pdf/2306.15033.pdf) focused on the productivity gained by GitHub Copilot, where half the developers were permitted access to Copilot while the other half were not. The results were striking, with Copilot users completing their projects 55% faster compared to the control group. The study even suggests that the adoption of AI coding tools like Copilot could potentially contribute to a remarkable $1.5 trillion boost in the global GDP. While this was just one study, it is evident that tools like Copilot can be used to write code faster, more efficiently, and with fewer errors. \n",
    "\n",
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Industry giants including Google, Meta, and OpenAI played pivotal roles in text Generative AI with significant releases such as PaLM, Galactica, ChatGPT and GPT4, respectively. ChatGPT was a tipping point in text Generative AI which brought LLMs to the center of the worlds attention. LLMs have the ability to generate coherent and contextually relevant text, making them invaluable for content creation, writing assistance, and creative storytelling. They can effectively analyze and organize vast amounts of textual data, enabling more efficient search engines and knowledge extraction systems. Meta's release of LLaMa set the stage for a series of impressive open-source alternatives to ChatGPT. Responding to growing demand, Google introduced Bard, an AI chatbot, as critics clamored for the search giant's response to the popular ChatGPT. Furthermore, game-changing advancements like QLoRA showcased the feasibility of fine-tuning Language Models (LLMs) on consumer-grade GPUs, extending the accessibility of this technology to a broader community.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21539eb8",
   "metadata": {
    "papermill": {
     "duration": 0.012828,
     "end_time": "2023-07-13T14:19:58.402530",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.389702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> ðŸ“Œ  Conclusion:\n",
    "    <ul>\n",
    "    <li> The promise of text and image generative AI, powered by LLMs, is both exhilarating and transformative. </li>\n",
    "    <li> These models have the potential to revolutionize various industries and domains, ranging from art and design, education, and beyond.</li>\n",
    "    <li> It is crucial to navigate this promising landscape responsibly. Ethical considerations, including addressing biases, privacy concerns, and the potential for misuse, must be at the forefront of development and deployment. </li>\n",
    "    <li>Striking the right balance between innovation and responsibility will ensure that the benefits of LLMs are harnessed while mitigating any potential risks.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ebf83",
   "metadata": {
    "papermill": {
     "duration": 0.013061,
     "end_time": "2023-07-13T14:19:58.429041",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.415980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9276b69",
   "metadata": {
    "papermill": {
     "duration": 0.012747,
     "end_time": "2023-07-13T14:19:58.455123",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.442376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"fwd\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 7. Looking Forward</span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#fwd\">Â¶</a></h1>\n",
    "<p style=\"text-align:center;\"><img src=\"https://i.imgur.com/8kmUi3i.png\" width=\"800\" height=\"600\" class=\"center\"/></p>\n",
    "<a href=\"https://unsplash.com/photos/oMpAz-DN-9I\"><p style=\"text-align:center\">Image credit Greg Rakozy</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc74ed",
   "metadata": {
    "papermill": {
     "duration": 0.012979,
     "end_time": "2023-07-13T14:19:58.481309",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.468330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Over the past few years, significant advancements in text-to-image models have propelled the creation of highly realistic and high-quality images. However, these advancements have also brought about a heightened concern regarding the proliferation of fake and harmful content. It is essential to approach the deployment of such models with a strong ethical framework and responsible practices while striking a balance with the technological advancements. This will be crucial to ensure the positive and beneficial applications of text-to-image generative AI while mitigating the risks associated with potential misuse. Apart from the potential to misuse these models, there have also been growing concerns regarding copyright violations for the images that these models were trained on. A [lawsuit](https://stablediffusionlitigation.com/)  filed by a group of artists against companies like Stability AI and Midjourney, claims that these models were trained on billions of images found on the internet, without the consent of the original artists. This case is still pending but it highlights a concern that must be acknowledged as the race to generate AI based images explodes. In a recent ruling, the US Copyright office announced a [policy](https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence) saying that AI-generated images are not protectable under current copyright law, as they â€œare not the product of human authorship.â€ This has signficant implications to creators and designers who plan to use AI based tools to create content. \n",
    "    <br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Language models have witnessed remarkable progress in recent years, with Large Language Models (LLMs) at the forefront of this advancement. While LLMs offer great promise, several pitfalls must be acknowledged and addressed before deploying such stytems broadly. One significant concern is the potential for bias in training data, which can perpetuate societal inequalities and reinforce existing biases. Ethical considerations surrounding privacy and data security must also be taken into account, as LLMs require vast amounts of data to train effectively. The copyright concerns seen in text-to-image models are also applicable to LLMs. In a [lawsuit](https://storage.courtlistener.com/recap/gov.uscourts.cand.403220/gov.uscourts.cand.403220.1.0.pdf) against GitHub, Microsoft, and OpenAI the plaintiffs allege that these companies violated copyright, contract, privacy, and business laws, among others, by using public source code pulled from GitHub to create GitHub's Copilot programming assistant. While this case is also pending, it highlights the need to carefully look at data that the model was trained on, before it is put into commercial applications. Model hallucination is also a concern where the model generates text that is incorrect, nonsensical, or not real. In a recent [case](https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c), a lawyer used ChatGPT to submit fictitious legal research in an aviation injury claim. This serves as an illustration of the potential dangers associated with relying on technology that is still undergoing evaluation, highlighting the need for appropriate safeguards and checks to ensure its safe and responsible use. Furthermore, the issue of explainability arises, as LLMs can be seen as black boxes, making it challenging to understand how they arrive at their conclusions.\n",
    "  <br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; Despite the pitfalls, LLMs hold tremendous potential and offer numerous promising possibilities. One of the key promises lies in their ability to enhance human-computer interaction. LLMs can empower individuals to access and navigate vast amounts of information, providing personalized insights and recommendations. Looking forward, addressing issues like model hallucination with techniques such as grounding, might be key to help improve the quality of model outputs. Grounding ensures that the  model is not only using the data on which it is trained, but it is also able to access external data sources to provide additional context and 'ground' the model to factual data. One approach to ground the model reponses with factual data was presented in the Retrieval Augmented Generation (RAG) [paper](https://arxiv.org/abs/2005.11401). RAG provides an architecture that adds an additional step where relevant documents on the topic are retrieved from an additional source like the internet, along with the original text that is input to the model. These two sources integrate all the information and give the model the capability to generate more factually correct answers while citing the relevant sources. \n",
    "<br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; The rapid advancement of LLMs have also resulted in the emergence of popular tools built on top of these LLMs like LangChain and AutoGPT. [LangChain](https://python.langchain.com/docs/get_started/introduction.html) is an open-source framework that allows developers to build applications using LLMs. It provides a number of features that make it easier to chain together different LLMs and data sources. LangChain's features include prompt templates that makes it easier to create different types of applications, such as chatbots, question-answering systems, and summarization tools. It also supports \"Agents\" which are components that use LLMs to decide what actions should be taken. This makes it possible to build more complex applications that can reason about the world and take appropriate actions. [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT) is an open source attempt to make LLMs like GPT4 fully autonomous. It was designed to provide targeted, goal-oriented solutions by segmenting larger objectives into a sequence of manageable, smaller subtasks. It then tirelessly executes these subtasks â€“ either indefinitely or until you choose to halt it, which is where the autonomous part comes in. Tools like LangChain and AutoGPT will continue to emerge in this ever evolving LLM landscape, and will play a signficant role in shaping how these models are used in the future. \n",
    "<br><br><span style=\"font-family:arial;color:black;font-size:15px;\">&nbsp;&nbsp;&nbsp;&nbsp; These past few years have witnessed an era of rapid innovation and transformative breakthroughs in Generative AI. As novel models and techniques continue to be developed, we can eagerly anticipate even more astonishing advancements in the years to come, further propelling the field into uncharted territory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29118db9",
   "metadata": {
    "papermill": {
     "duration": 0.012926,
     "end_time": "2023-07-13T14:19:58.507351",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.494425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">ðŸ“Œ As we move forward, collaboration between researchers, policymakers, and society at large will be essential to shape the future of text and image generative AI and LLMs. Together, we can unlock the full potential of these technologies, unleashing a new era of creativity, productivity, and human-computer symbiosis. By embracing this promise responsibly, we can create a future where LLMs enrich our lives, inspire innovation, and contribute to the betterment of society as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7168767",
   "metadata": {
    "papermill": {
     "duration": 0.012811,
     "end_time": "2023-07-13T14:19:58.533368",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.520557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ea99f",
   "metadata": {
    "papermill": {
     "duration": 0.012945,
     "end_time": "2023-07-13T14:19:58.559355",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.546410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"ref\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 8. References</span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#ref\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b3c91",
   "metadata": {
    "papermill": {
     "duration": 0.01304,
     "end_time": "2023-07-13T14:19:58.585431",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.572391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. _Attention Is All You Need_ https://arxiv.org/abs/1706.03762\n",
    "2. _Generating Wikipedia by Summarizing Long Sequences_ https://arxiv.org/pdf/1801.10198.pdf\n",
    "3. DALL-E: _Zero-Shot Text-to-Image Generation_ https://arxiv.org/abs/2102.12092\n",
    "4. CLIP: _Learning Transferable Visual Models From Natural Language Supervision_ https://arxiv.org/abs/2103.00020\n",
    "5. PaLM: _Scaling Language Modeling with Pathways_ https://arxiv.org/pdf/2204.02311v5.pdf\n",
    "6. DALL-E 2: _Hierarchical Text-Conditional Image Generation with CLIP Latents_ https://arxiv.org/pdf/2204.06125v1.pdf\n",
    "7. MAKE-A-VIDEO: _Text-to-video generation without text-video data_ https://arxiv.org/pdf/2209.14792.pdf\n",
    "7. Galactica: _Galactica: A Large Language Model for Science_ https://galactica.org/static/paper.pdf\n",
    "8. RLHF: _Training language models to follow instructions with human feedback_ https://arxiv.org/abs/2203.02155\n",
    "9. _A Survey of Large Language Models_ https://arxiv.org/abs/2303.18223\n",
    "10. _QLoRA: Efficient Finetuning of Quantized LLMs_ https://arxiv.org/abs/2305.14314\n",
    "11. GPT4: https://openai.com/research/gpt-4\n",
    "12. _Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle_ https://arxiv.org/abs/2306.15033\n",
    "13. _AI image generators are 21st-century collage tools that violate the rights of millions of artists_ https://stablediffusionlitigation.com/ \n",
    "14. _Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence_: https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence\n",
    "15. _A brave new world of software piracy_ https://storage.courtlistener.com/recap/gov.uscourts.cand.403220/gov.uscourts.cand.403220.1.0.pdf\n",
    "16. _Lawyers submitted bogus case law created by ChatGPT. A judge fined them $5,000_ https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c\n",
    "17. RAG: _Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks_ https://arxiv.org/abs/2005.11401\n",
    "18. _LangChain_ https://python.langchain.com/docs/get_started/introduction.html\n",
    "19. _AutoGPT_ https://github.com/Significant-Gravitas/Auto-GPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a16642",
   "metadata": {
    "papermill": {
     "duration": 0.013607,
     "end_time": "2023-07-13T14:19:58.612596",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.598989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71449d",
   "metadata": {
    "papermill": {
     "duration": 0.013171,
     "end_time": "2023-07-13T14:19:58.640687",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.627516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"citations\"><p style=\"text-align:center;\"><span style=\"font-family:Palatino;color:blue;font-size:40px;\"> 9. Citations</span></p><a class=\"anchor-link\" href=\"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai#citations\">Â¶</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8859cd",
   "metadata": {
    "papermill": {
     "duration": 0.012709,
     "end_time": "2023-07-13T14:19:58.666497",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.653788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-family:arial;color:black;font-size:15px;\"><strong>AI-Generated Content: </strong> This report uses tools like ChatGPT and Bard in some sections to help rephrase the original content written by me (Trushant). I strongly believe that AI tools should be embraced and used to improve productivity and generate higher quality content for the consumers of the content. Any text that was rephrased, was checked for factual and syntactical correctness and to make sure that the writing style was consistent with the one intended by me for this AI Report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fa40e",
   "metadata": {
    "papermill": {
     "duration": 0.013299,
     "end_time": "2023-07-13T14:19:58.693410",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.680111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538a767",
   "metadata": {
    "papermill": {
     "duration": 0.01276,
     "end_time": "2023-07-13T14:19:58.719392",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.706632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9f10e0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-07-13T14:19:58.748598Z",
     "iopub.status.busy": "2023-07-13T14:19:58.748035Z",
     "iopub.status.idle": "2023-07-13T14:19:58.792370Z",
     "shell.execute_reply": "2023-07-13T14:19:58.791492Z"
    },
    "papermill": {
     "duration": 0.061232,
     "end_time": "2023-07-13T14:19:58.794673",
     "exception": false,
     "start_time": "2023-07-13T14:19:58.733441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type  \\\n",
      "0  essay_category   \n",
      "1       essay_url   \n",
      "2   feedback1_url   \n",
      "3   feedback2_url   \n",
      "4   feedback3_url   \n",
      "\n",
      "                                                                                                         value  \n",
      "0                                                                                                Generative AI  \n",
      "1                                       https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai  \n",
      "2                 https://www.kaggle.com/code/keerthanasrija/generative-ai-kaggle-2023-report/comments#2342480  \n",
      "3  https://www.kaggle.com/code/sanjushasuresh/generative-ai-creating-machines-more-human-like/comments#2343226  \n",
      "4                             https://www.kaggle.com/code/yossra/the-generative-ai-hype-cycle/comments#2343262  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = None\n",
    "submission = pd.read_csv(\"/kaggle/input/2023-kaggle-ai-report/sample_submission.csv\")\n",
    "submission[\"value\"] = [\"Generative AI\", \n",
    "                       \"https://www.kaggle.com/code/trushk/2023-kaggle-ai-report-generative-ai\",\n",
    "                       \"https://www.kaggle.com/code/keerthanasrija/generative-ai-kaggle-2023-report/comments#2342480\",\n",
    "                       \"https://www.kaggle.com/code/sanjushasuresh/generative-ai-creating-machines-more-human-like/comments#2343226\",\n",
    "                       \"https://www.kaggle.com/code/yossra/the-generative-ai-hype-cycle/comments#2343262\"\n",
    "                      ]\n",
    "print(submission.head())\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.332359,
   "end_time": "2023-07-13T14:19:59.630541",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-13T14:19:45.298182",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
